## AlexNet(2012)

### Contribution

- ImageNet 대회에서 전년도 대비 약 9% 이상의 성능 향상으로 압도적인 성능으로 1위를 하였습니다.
- GPU를 사용하여 매우 의미 있는 결과를 얻어 이후 CNN 구조를 설계할 때 GPU를 사용하는 것이 대세가 되었습니다.
- 현재 classification 모델의 표준인 <CNN-FC> 구조를 제안하였습니다.
- 성능 향상과 training 시간을 향상시키기 위한 여러가지 기능(ReLU, LRN, Data augmentation, Dropout)을 포함하였습니다.

----
### Architexture
<img src="/images/AlexNet.png" width="500" height="200">  

- 위 그림의 설명과 같이 5 Convolution Layers, 3 Fully-Connected Layers, 1000 ways Softmax로 구성되어있습니다.
- 당시 GPU의 스펙이 낮아 2개의 GPU를 병렬로 사용하여 학습하였습니다.(GTX580 3GB사용)

----
### Algorithm
#### ReLU
<img src="/images/ReLU.png" width="300" height="200">

지금은 기본적으로 사용하지만 tanh, sigmoid등을 사용할 시기였을 때, ReLU를 사용함으로써 학습 속도를 개선하였습니다.
ReLU는 0보다 작은 값은 0으로 사용하고, 0보다 큰 값은 해당 값을 그대로 사용하는 방법입니다. 

#### LRN(Local Response Normalization)
ReLU는 무제한의 활성화가 있기때문에 LRN이 필요합니다.
LRN은 output에서 convolution feature map이 나오면 그중에서 일정 부분만 높게 activation되게 해주는 작업입니다. AlexNet에서는 해당 작업을 수행해 주었다. 첨언하자면 지금은 성능상 큰 이점이 없어서 잘 사용하지 않습니다.

#### Regularization
- Data augmentation  
AlexNet에서는 256 *
256의 original Image를 224 * 224의 Smaller Patch로 떠서 하나의 이미지 안에서 데이터를 32 * 32개를 늘릴 수 있고, 좌우 반전까지 하면 그의 *2배를 해주어 총 2048배의 데이터를 늘릴 수 있습니다.

- Dropout  
Dropout은 Network의 일부를 생략하여 다른 Model을 학습한 것과 같은 효과를 얻어 overfitting을 개선하는 방법입니다. AlexNet에서는 test할 때 모든 뉴런을 사용하지만, output에 0.5를 곱해주었다. 이 방법은 처음이자 마지막으로 수행되었다고 합니다.

## ZFNet(2013)
### Contribution

- ZFNet의 구조는 AlexNet에서 GPU를 하나만 쓰고 일부 convolution layer의 kernel 사이즈와 stride를 일부 조절해주었습니다.
- ZFNet은 CNN을 가시화하여 CNN의 중간 과정을 눈으로 보고 개선 방향을 파악할 수 있는 방법을 만들었습니다.(Visualizing)

### Architexture
<img src="/images/ZFNet.png" width="500" height="200">

- layers1의 filter 사이즈를 11 * 11 -> 7 * 7, stride를 4 -> 1로 수정해주었고, 이에 따라 layers2의 stride를 1 -> 2로 수정하였습니다.

### Algorithm
#### Visualizing
CNN은 convolution계산 후 활성 함수를 통해 feature map을 생성하고, pooling하여 이미지를 축소 시키는 것을 반복하는데 이 과적을 반대로 해주어 원본 이미지에 mapping할 수 있는 이미지를 생성 할 수 있습니다.  <img src="/images/ZFNet_1.png" width="250" height="350">  
max-pooling은 이미지를 축소 시키는 과정에서 가장 강한 자극을 전달하는데 이 과정을 반대로하면 어느 부분이 강한 자극인지를 알 수 없는 문제가 생깁니다. Visualizing은 가장 강한 자극의 위치를 가지고 있도록 하여 이와 같은 문제를 해결하였습니다.## GoogLeNet(2014)
### Contribution
- 이전(~2013)의 CNN과 달리 망의 깊이가 깊어지게 되었습니다.
- AlexNet과 비교하여 불과 2년만에 약 10% 정도의 에러율을 낮추었습니다.
- 효과적으로 차원을 줄이면서 망을 깊게 할 수 있는 방법(Inception Module)을 개발하였습니다.
- GoogLeNet은 AlexNet에 비해 망의 깊이는 훨씬 깊은데 free parameter의 수는 1/12수준이고, 전체 연산량도 AlexNet에 비해 적습니다.
- GoogLeNet에선 vanishing gradient문제를 극복하기 위하여 Auxiliary classifier를 중간 2곳에 두었습니다.

### Architexture
<img src="/images/GoogLeNet_1.png" width="500" height="250">   
- 위 그림을 보면 독특하게 Auxiliary classifier 블락이 있는것을 확인 할 수 있습니다.
- 9개의 Inception Module이 적용되었습니다.
### Algorithm


#### NIN(Network In Network)
<img src="/images/MLP.png" width="330" height="200">  
- convolution kernel 대신에 MLP를 사용합니다.  
- MLP는 convolution kernel 보다 non-linear한 성질을 잘 활용할 수 있기 때문에 feature를 추출하는 능력이 우수합니다.  
- 1 * 1 convolution을 사용하여 feature-map을 줄였습니다.  
- CNN의 최종단에서 흔히 보이는 Fully-connected NN 대신에 Global average pooling을 사용합니다.    


#### Inception
<img src="/images/GoogLeNet.png" width="500" height="250">    
- 원래는 (a)의 구조를 고안하였지만 3 * 3과 5 * 5는 연산량이 expensive하기 때문에 (b)와 같이 1 * 1을 통하여 feature-map의 차원을 줄여 연산량의 균형을 맞춰주었습니다.  
- 다양한 크기의 convolution kernel(그림의 파란색 부분)을 통해 다양한 scale의 feature를 효과적으로 추출하는 것이 가능해졌습니다.
- Max-Pooling의 경우 1 * 1이 뒤에있는데 이는 출력 채널의 크기를 맞추기 위함입니다. 

#### Auxiliary classifier
- back-propagation시에 Auxiliary classifier와 최종 출력으로부터의 정상적인 back-propagation결과를 결합시킵니다.
- 학습을 도와주기 위한 도우미의 역할이며, 학습을 끝난 후에는 제거합니다.

## VGGNet(2014)
### Contribution
- 2014년 ILSVRC에서 GoogLeNet와 근소한 차이로 2위를 차지하였습니다. 하지만 GoogLeNet보다 훨씬 구조가 간단하여 더 많이 사용되는 편입니다.  
- 전반적인 구조는 LeNet5, AlexNet와 크게 다르지 않지만 깊이에서 차이가 납니다.
- GoogLeNet(5 milion)에 비하여 VGGNet(133 milion)의 파라미터 개수가 많다는 단점이 있습니다.


### Architexture
<img src="/images/VGGNet_1.png" width="400" height="300"> 
- 망의 깊이가 어떤 영향을 끼치는지를 확인하기 위해 가장 단순한 3 * 3 convolution layer를 겹쳐서 사용하였습니다.  

### Algorithm
- vanishing/exploding gradient의 문제를 해결하기 위해서 VGGNet는 11-layer 구조의 학습 결과를 더 깊은 layer(13,16,19)의 파라미터 초기화 시에 이용함으로써 문제를 해결함과 동시에 학습시간도 줄여주었습니다.  

#### Factorizing Convolutions
큰 필터 크기를 갖는 convolution kernel을 인수 분해 하면, 작은 kernel 여러개로 구성된 deep network를 만들 수 있으며, parameter의 수가 더 줄어들면서 망은 깊어지는 효과를 얻을 수 있습니다.  
5 * 5 convolution은 2 layer의 3 * 3 convolution으로 구현 할 수 있으며, free parameter는 28%만큼 절감 할 수 있습니다.  
인수분해를 symmetry를 유지하는 방식으로도 가능하지만, symmetry를 유지 하지 않고 row, column방향으로 인수 분해하는 것도 가능합니다.(3 * 3 -> 1 * 3, 3 * 1)


## ResNet(2015)
### Contribution

- GoogLeNet보다 약 두배의 성능이 좋아졌으며, error율이 3.57%로 사람의 오차율(5%)보다 더 좋은 결과를 얻었습니다.  
- classification뿐만 아니라 localization, detection 분야에서도 압도적인 성능을 보였다.


### Architexture
#### Deeper Bottleneck Architecture
<img src="/images/Bottlenect.png" width="300" height="200">   
- 위의 그림처럼 residual function은 1 * 1, 3 * 3, 1 * 1로 구성되어있습니다. 이는 Residual Learning을 위해선 입력과 출력의 차원이 같아야하기 때문이다.
- 이러한 Bottleneck 구조는 차원을 줄였다가 다시 차원을 늘려주어 GoogLeNet의 Inception 구조처럼 연산량을 줄여주게 됩니다.  

### Algorithm

#### Residual Learning

<img src="/images/Residual.png" width="300" height="200"> 

- 출력 H(x)를 얻는 것이 목표가 아니라 H(x)-x를 얻는것이 목표입니다.
- 입력에서 바로 출력으로 연결되는 shortcut 연결이 존재합니다.


## Reference

[ImageNet Classification with Deep Convolutional
Neural Networks](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)  [ReLU](http://pythonkim.tistory.com/40)  
[LRN](https://translate.google.co.kr/translate?hl=ko&sl=en&u=https://prateekvjoshi.com/2016/04/05/what-is-local-response-normalization-in-convolutional-neural-networks/&prev=search)   
[최신논문으로 시작하는 딥러닝_최성준](http://m.edwith.org/deeplearningchoi)  
[라온피플](https://m.blog.naver.com/PostView.nhn?blogId=laonple&logNo=220654387455&proxyReferer=https%3A%2F%2Fwww.google.co.kr%2F)
